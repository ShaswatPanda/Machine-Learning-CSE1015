{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing librairies\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn library: For SVM\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "import itertools\n",
    "\n",
    "# Matplotlib library to plot the charts\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "# Library for the statistic data vizualisation\n",
    "import seaborn\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../input/creditcard.csv') # Reading the file .csv\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraud = df[df['Class'] == 1] # Recovery of fraud data\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(df_fraud['Time'], df_fraud['Amount']) # Display fraud amounts according to their time\n",
    "plt.title('Scratter plot amount fraud')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amount')\n",
    "plt.xlim([0,175000])\n",
    "plt.ylim([0,2500])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_big_fraud = df_fraud[df_fraud['Amount'] > 1000].shape[0] # Recovery of frauds over 1000\n",
    "print('There are only '+ str(nb_big_fraud) + ' frauds where the amount was bigger than 1000 over ' + str(df_fraud.shape[0]) + ' frauds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_fraud = len(data[data.Class == 1])\n",
    "number_no_fraud = len(data[data.Class == 0])\n",
    "print('There are only '+ str(number_fraud) + ' frauds in the original dataset, even though there are ' + str(number_no_fraud) +' no frauds in the dataset.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The accuracy of the classifier then would be : \"+ str((284315-492)/284315)+ \" which is the number of good classification over the number of tuple to classify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "seaborn.heatmap(df_corr, cmap=\"YlGnBu\") # Displaying the Heatmap\n",
    "seaborn.set(font_scale=2,style='white')\n",
    "\n",
    "plt.title('Heatmap correlation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = df_corr['Class'] # Retrieving the correlation coefficients per feature in relation to the feature class\n",
    "df_rank = pd.DataFrame(rank) \n",
    "df_rank = np.abs(df_rank).sort_values(by='Class',ascending=False) # Ranking the absolute values of the coefficients\n",
    "                                                                  # in descending order\n",
    "df_rank.dropna(inplace=True) # Removing Missing Data (not a number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_all = df[0:150000] # We cut in two the original dataset\n",
    "df_train_1 = df_train_all[df_train_all['Class'] == 1] # We seperate the data which are the frauds and the no frauds\n",
    "df_train_0 = df_train_all[df_train_all['Class'] == 0]\n",
    "print('In this dataset, we have ' + str(len(df_train_1)) +\" frauds so we need to take a similar number of non-fraud\")\n",
    "\n",
    "df_sample=df_train_0.sample(300)\n",
    "df_train = df_train_1.append(df_sample) # We gather the frauds with the no frauds. \n",
    "df_train = df_train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
